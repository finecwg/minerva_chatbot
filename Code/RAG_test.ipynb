{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/01_ByMember/wgchoi/minerva_chatbot/Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "langchain\n",
    "langchain-community\n",
    "llama-parse\n",
    "fastembed\n",
    "chromadb\n",
    "python-dotenv\n",
    "langchain-groq\n",
    "chainlit\n",
    "fastembed\n",
    "unstructured[md]\n",
    "python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llamaparse_api_key = os.getenv('LLAMA_CLOUD_API_KEY') #* https://cloud.llamaindex.ai/api-key\n",
    "groq_api_key = os.getenv('GROQ_API_KEY') #* https://console.groq.com/docs/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LLAMAPARSE #####\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "#\n",
    "import joblib\n",
    "import os\n",
    "import nest_asyncio  # noqa: E402\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_file_list(*file_dirs):\n",
    "    html_files = []\n",
    "\n",
    "    # Function to list HTML files in a directory\n",
    "    def list_html_files(directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.html'):\n",
    "                html_files.append(os.path.join(directory, filename))\n",
    "\n",
    "    # List HTML files from each provided directory\n",
    "    for directory in file_dirs:\n",
    "        list_html_files(directory)\n",
    "\n",
    "    return html_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_parse_data():\n",
    "    data_file = \"./Data/parsed_data_240529_cms.pkl\" ##TODO\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "        # Load the parsed data from the file\n",
    "        parsed_data = joblib.load(data_file)\n",
    "    else:\n",
    "        \n",
    "        docs = get_html_file_list('Data/scrapped_html/sitemap-cms') ##TODO\n",
    "    \n",
    "        # Perform the parsing step and store the result in llama_parse_documents\n",
    "        parsingInstructionUber10k = \"\"\"The provided document contains information about Minerva University.\n",
    "        This form provides detailed information about Minerva University and their educational programs, and stories.\\\n",
    "        It contains many tables and figures.\n",
    "        Try to be precise while answering the questions\"\"\"\n",
    "        parser = LlamaParse(api_key=llamaparse_api_key,\n",
    "                            result_type=\"markdown\",\n",
    "                            parsing_instruction=parsingInstructionUber10k,\n",
    "                            max_timeout=5000,)\n",
    "        llama_parse_documents = parser.load_data(docs)\n",
    "\n",
    "\n",
    "        # Save the parsed data to a file\n",
    "        print(\"Saving the parse results in .pkl format ..........\")\n",
    "        joblib.dump(llama_parse_documents, data_file)\n",
    "\n",
    "        # Set the parsed data to the variable\n",
    "        parsed_data = llama_parse_documents\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector database\n",
    "def create_vector_database():\n",
    "    \"\"\"\n",
    "    *Creates a vector database using document loaders and embeddings.\n",
    "\n",
    "    *This function loads urls,\n",
    "    *splits the loaded documents into chunks, transforms them into embeddings using OllamaEmbeddings,\n",
    "    *and finally persists the embeddings into a Chroma vector database.\n",
    "\n",
    "    \"\"\"\n",
    "    db_directory = \"Data/test-db-240529-cms\"\n",
    "    os.makedirs(db_directory, exist_ok =True)\n",
    "    os.chmod(db_directory, 0o755)\n",
    "\n",
    "\n",
    "\n",
    "    # Call the function to either load or parse the data\n",
    "    llama_parse_documents = load_or_parse_data()\n",
    "    print(llama_parse_documents[0].text[:300])\n",
    "\n",
    "    with open('Data/test-db-240529-cms/output.md', 'a') as f:  #TODO\n",
    "        for doc in llama_parse_documents:\n",
    "            f.write(doc.text + '\\n')\n",
    "\n",
    "    markdown_path = \"Data/test-db-240529-cms/output.md\" ##TODO\n",
    "    loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "   #loader = DirectoryLoader('data/', glob=\"**/*.md\", show_progress=True)\n",
    "    documents = loader.load()\n",
    "    # Split loaded documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    #len(docs)\n",
    "    print(f\"length of documents loaded: {len(documents)}\")\n",
    "    print(f\"total number of document chunks generated :{len(docs)}\")\n",
    "    #docs[0]\n",
    "\n",
    "    # Initialize Embeddings\n",
    "    embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "    # Create and persist a Chroma vector database from the chunked documents\n",
    "    vs = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embed_model,\n",
    "        persist_directory=db_directory,  # Local mode with in-memory storage only\n",
    "        collection_name=\"rag\"\n",
    "    )\n",
    "\n",
    "    #query it\n",
    "    #query = \"what is the agend of Financial Statements for 2022 ?\"\n",
    "    #found_doc = qdrant.similarity_search(query, k=3)\n",
    "    #print(found_doc[0][:100])\n",
    "    #print(qdrant.get())\n",
    "\n",
    "    print('Vector DB created successfully !')\n",
    "    return vs,embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files:   0%|          | 0/426 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files: 100%|██████████| 426/426 [14:40<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the parse results in .pkl format ..........\n",
      "#\n",
      "\n",
      "# Minerva University\n",
      "\n",
      "# Academics\n",
      "\n",
      "# Admissions\n",
      "\n",
      "# About\n",
      "\n",
      "# Stories\n",
      "\n",
      "# Events\n",
      "\n",
      "# MINERVA VOICES\n",
      "\n",
      "Connecting to the Classroom: A Minerva Faculty Perspective\n",
      "\n",
      "by Rohan Shekhar, Ph.D., Professor of Computational Sciences\n",
      "\n",
      "May 4, 2018\n",
      "---\n",
      "#\n",
      "\n",
      "# Minerva University Information\n",
      "\n",
      "# About Minerva Universit\n",
      "length of documents loaded: 1\n",
      "total number of document chunks generated :1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 71089.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB created successfully !\n"
     ]
    }
   ],
   "source": [
    "vs,embed_model = create_vector_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 19803.14it/s]\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 63743.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# 240528 - merging cms + static\n",
    "\n",
    "vectorstore_1 = Chroma(embedding_function=FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\"),\n",
    "                      persist_directory=\"Data/test-db-240529-cms-and-static\",\n",
    "                      collection_name=\"rag\")\n",
    "\n",
    "vectorstore_2 = Chroma(embedding_function=FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\"),\n",
    "                      persist_directory=\"Data/test-db-240529-static\",\n",
    "                      collection_name=\"rag\")\n",
    "\n",
    "vectorstore_2_data = vectorstore_2._collection.get(include=['documents','metadatas','embeddings'])\n",
    "\n",
    "vectorstore_1._collection.add(\n",
    "     embeddings=vectorstore_2_data['embeddings'],\n",
    "     metadatas=vectorstore_2_data['metadatas'],\n",
    "     documents=vectorstore_2_data['documents'],\n",
    "     ids=vectorstore_2_data['ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 22501.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"You are an tutor who have to give information about Minerva University to students who are curious about Minerva University.\\n\\nThis interaction concludes with your one reply, as a markdown format.\\n\\nUse the following pieces of information to answer the student's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: {context}\\nQuestion: {question}\\n\\nOnly return the helpful answer below and nothing else.\\nAlso, please add that your response is based on the user provided information, and it is essential to consult with a qualified veterinarian.\\nHelpful answer:\\n\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatGroq(temperature=0.1,\n",
    "                      model_name=\"llama3-8b-8192\",\n",
    "                      api_key=os.getenv('GROQ_API_KEY'),)\n",
    "vectorstore = Chroma(embedding_function=FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\"),\n",
    "                      persist_directory=\"Data/test-db-240529-cms-and-static\",\n",
    "                      collection_name=\"rag\")\n",
    " \n",
    "retriever=vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "custom_prompt_template = \"\"\"You are an tutor who have to give information about Minerva University to students who are curious about Minerva University.\n",
    "\n",
    "This interaction concludes with your one reply, as a markdown format.\n",
    "\n",
    "Use the following pieces of information to answer the student's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Also, please add that your response is based on the user provided information, and it is essential to consult with a qualified veterinarian.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "#\n",
    "prompt = set_custom_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat_model,\n",
    "                               chain_type=\"stuff\",\n",
    "                               retriever=retriever,\n",
    "                               return_source_documents=True,\n",
    "                               chain_type_kwargs={\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Who is the president of Minerva University?\"\"\"\n",
    "\n",
    "response = qa.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided information, the President of Minerva University is Mike Magee.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Contact: info@minerva.edu\\n\\nMinerva University\\n\\nAbout Minerva University\\n\\nMinerva University is an independent, non-profit educational institution accredited by Western Senior Colleges and Universities Commission (WASC). The Minerva name, logo, and trade dress are trademarks of Minerva Project.\\n\\n© 2024. Minerva Project, Inc. All Rights Reserved.\\n\\nMinerva University\\n\\nAcademics\\n\\nAdmissions\\n\\nAbout\\n\\nStories\\n\\nEvents\\n\\nMINERVA VOICES\\n\\nA Letter from Teri Cannon, Minerva University Founding President\\n\\nLetter from the Founding President\\n\\nApril 20, 2022\\n\\nMinerva University\\n\\nWelcome to Minerva University\\n\\nThis form provides detailed information about Minerva University and their educational programs, and stories. It contains many tables and figures.\\n\\nMessage from the President\\n\\nDear Friends of Minerva University,\\n\\nAs we look to build on our remarkable progress and expand access to our innovative education model to help more thinkers, leaders, and innovators drive positive change in our world, I am delighted to share the news that the Board has named Mike Magee as Minerva University’s next President.\\n\\nHelping to build Minerva these last 10 years and serving as Minerva University’s Founding President has been an honor of a lifetime for me. I have accomplished what I set out to do for Minerva and am confident the time is right to pass the baton to new leadership at this important stage of the University’s growth.\\n\\nTo ensure a smooth transition as Mike steps into this role, I will continue to be part of this amazing community, at least until next summer, serving in an advisory capacity.\\n\\nAbout Mike Magee\\n\\nMike Magee has devoted his life’s work to social change through education. He is uniquely qualified for the role of President at Minerva University, with a clear sense of purpose, a passion for breaking barriers, and erasing boundaries.', metadata={'source': 'Data/test-db-240529-cms/output.md'}),\n",
       " Document(page_content='Contact: info@minerva.edu\\n\\nMinerva University\\n\\nMinerva University\\n\\nMinerva University is an independent, non-profit educational institution accredited by Western Senior Colleges and Universities Commission (WASC). The Minerva name, logo, and trade dress are trademarks of Minerva Project.\\n\\n© 2024. Minerva Project, Inc. All Rights Reserved.\\n\\nMinerva University\\n\\nAcademics\\n\\nAdmissions\\n\\nAbout\\n\\nStories\\n\\nEvents\\n\\nMINERVA VOICES\\n\\nA Letter from Mike Magee, Minerva University President\\n\\nLetter from the President | 2022\\n\\nApril 20, 2022\\n\\nMinerva University\\n\\nWelcome to Minerva University\\n\\nThis form provides detailed information about Minerva University and their educational programs, and stories. It contains many tables and figures.\\n\\nMessage from the President\\n\\nDear Minerva Community,\\n\\nI couldn’t be more pleased for the opportunity to become Minerva University’s next President. I want to thank our Founder and Chancellor Ben Nelson, Founding President Teri Cannon, the Board of Trustees and the faculty and staff who I’ve had the pleasure of meeting for their warm welcome and the honor to lead Minerva forward. In many respects, stepping into this role is a culmination of a series of personal and professional experiences that have shaped my sense of purpose, guided my career in education, and prepared me to now help take this remarkable university into the future at a time when its mission is undeniably essential. As I get to know all of you, I want to begin by sharing my story.\\n\\nBackground Story', metadata={'source': 'Data/test-db-240529-cms/output.md'}),\n",
       " Document(page_content='Mike most recently served as CEO of Chiefs for Change, leading a trailblazing effort to create the nation’s premier leadership development program for aspiring K-12 leaders.\\n\\nMinerva University\\n\\nAbout Minerva University\\n\\nMinerva University was founded with an innate sense of optimism and hope inspired by an expansive horizon of possibility. The university has made a monumental impact on leadership diversity in public education.\\n\\nPrior to his role at Minerva University, the current President served as the Co-founder and CEO of the Rhode Island Mayoral Academies, where he created a statewide network of regional, racially, and economically integrated public schools. He is a graduate of Holy Cross University with a Ph.D. in English from the University of Pennsylvania, and began his career in education as a university professor.\\n\\nAccreditation\\n\\nMinerva University is an independent, accredited university with new leadership in place. The university is well-positioned to accelerate its vital mission, strengthen its financial foundation, and enter its next chapter of growth and development.\\n\\nContact Information\\n\\nAddress: 14 Mint Plaza, Suite 300, San Francisco, CA 94103\\n\\nEmail: info@minerva.edu\\n\\nPrograms Offered\\n\\nUndergraduate Programs\\n\\nMinerva University offers a range of undergraduate programs.\\n\\nGraduate Programs\\n\\nMinerva University also provides various graduate programs.\\n\\nAdditional Resources and Opportunities\\n\\nNon-Discrimination Policy\\n\\nVisiting Scholars Year\\n\\nPlease join us in welcoming our new President to the Minerva family.\\n\\nSincerely,\\n\\nTeri Cannon\\n\\nMinerva University\\n\\nWelcome to Minerva University\\n\\nThis form provides detailed information about Minerva University and their educational programs, and stories. It contains many tables and figures.\\n\\nPress & Media\\n\\nUndergraduate\\n\\nUniversal strategies for designing and delivering effective and engaging online courses\\n\\nCareers\\n\\nConnect\\n\\nEvents\\n\\nStudent Handbook\\n\\nGraduate Student Handbook\\n\\nAnnual Security Report', metadata={'source': 'Data/test-db-240529-cms/output.md'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     application\u001b[38;5;241m.\u001b[39mrun_polling()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m application\u001b[38;5;241m.\u001b[39madd_handler(CommandHandler(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, start))\n\u001b[1;32m     19\u001b[0m application\u001b[38;5;241m.\u001b[39madd_handler(MessageHandler(filters\u001b[38;5;241m.\u001b[39mTEXT \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39mfilters\u001b[38;5;241m.\u001b[39mCOMMAND, handle_message))\n\u001b[0;32m---> 21\u001b[0m \u001b[43mapplication\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/02_ByProject/AIChatVet/VetConference/.conda/lib/python3.11/site-packages/telegram/ext/_application.py:871\u001b[0m, in \u001b[0;36mApplication.run_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, read_timeout, write_timeout, connect_timeout, pool_timeout, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_callback\u001b[39m(exc: TelegramError) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_error(error\u001b[38;5;241m=\u001b[39mexc, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdater_coroutine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_polling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbootstrap_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_pending_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_pending_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if there is an error in fetching updates\u001b[39;49;00m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclose_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclose_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_signals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/02_ByProject/AIChatVet/VetConference/.conda/lib/python3.11/site-packages/telegram/ext/_application.py:1099\u001b[0m, in \u001b[0;36mApplication.__run\u001b[0;34m(self, updater_coroutine, stop_signals, close_loop)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close_loop:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/02_ByProject/AIChatVet/VetConference/.conda/lib/python3.11/asyncio/unix_events.py:68\u001b[0m, in \u001b[0;36m_UnixSelectorEventLoop.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mis_finalizing():\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_handlers):\n",
      "File \u001b[0;32m/data/02_ByProject/AIChatVet/VetConference/.conda/lib/python3.11/asyncio/selector_events.py:88\u001b[0m, in \u001b[0;36mBaseSelectorEventLoop.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot close a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_closed():\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    }
   ],
   "source": [
    "from telegram import Update, Bot\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "\n",
    "\n",
    "TELEGRAM_TOKEN = '7231454526:AAH8ZAqt9USSWa2u6ojJHEKFeJYNRkovR2U'\n",
    "\n",
    "async def start(update: Update, context: CallbackContext) -> None:\n",
    "    await update.message.reply_text('Hi! Ask me anything about Minerva University.')\n",
    "\n",
    "async def handle_message(update: Update, context: CallbackContext) -> None:\n",
    "    query = update.message.text\n",
    "    response = qa.invoke({\"query\": query})\n",
    "    await update.message.reply_text(response['result'])\n",
    "\n",
    "def main() -> None:\n",
    "    application = Application.builder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "\n",
    "    application.run_polling()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
